In various domains such as, but not limited to, statistics, signal processing, finance, econometrics, manufacturing, networking and data mining, anomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.In particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts in activity. This pattern does not adhere to the common statistical definition of an outlier as a rare object, and many outlier detection methods (in particular unsupervised methods) will fail on such data, unless it has been aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro clusters formed by these patterns.Three broad categories of anomaly detection techniques exist. Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal by looking for instances that seem to fit least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as "normal" and "abnormal" and involves training a classifier (the key difference to many other statistical classification problems is the inherent unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set, and then test the likelihood of a test instance to be generated by the learnt model.\n\n\n== Applications ==\nAnomaly detection is applicable in a variety of domains, such as intrusion detection, fraud detection, fault detection, system health monitoring, event detection in sensor networks, and detecting ecosystem disturbances. It is often used in preprocessing to remove anomalous data from the dataset. In supervised learning, removing the anomalous data from the dataset often results in a statistically significant increase in accuracy.\n\n\n== Popular techniques ==\nSeveral anomaly detection techniques have been proposed in literature. Some of the popular techniques are:\n\nDensity-based techniques (k-nearest neighbor, local outlier factor, isolation forests, and many more variations of this concept).\nSubspace-, correlation-based and tensor-based  outlier detection for high-dimensional data.\nOne-class support vector machines.\nReplicator neural networks., autoencoders, variational autoencoders, long short-term memory neural networks\nBayesian Networks.\nHidden Markov models (HMMs).\nCluster analysis-based outlier detection.\nDeviations from association rules and frequent itemsets.\nFuzzy logic-based outlier detection.\nEnsemble techniques, using feature bagging, score normalization and different sources of diversity.The performance of different methods depends a lot on the data set and parameters, and methods have little systematic advantages over another when compared across many data sets and parameters.\n\n\n== Application to data security ==\nAnomaly detection was proposed for intrusion detection systems (IDS) by Dorothy Denning in 1986. Anomaly detection for IDS is normally accomplished with thresholds and statistics, but can also be done with soft computing, and inductive learning. Types of statistics proposed by 1999 included profiles of users, workstations, networks, remote hosts, groups of users, and programs based on frequencies, means, variances, covariances, and standard deviations.  The counterpart of anomaly detection in intrusion detection is misuse detection.\n\n\n== Software ==\nELKI is an open-source Java data mining toolkit that contains several anomaly detection algorithms, as well as index acceleration for them.\n\n\n== Datasets ==\nAnomaly detection benchmark data repository of the Ludwig-Maximilians-Universit\xe4t M\xfcnchen; Mirror at University of S\xe3o Paulo.\nODDS \u2013 ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains.\n\n\n== See also ==\nChange detection\nStatistical process control\nNovelty detection\nHierarchical temporal memory\n\n\n== References ==