DeepDream is a computer vision program created by Google engineer Alexander Mordvintsev which uses a convolutional neural network to find and enhance patterns in images via algorithmic pareidolia, thus creating a dream-like hallucinogenic appearance in the deliberately over-processed images.Google's program popularized the term (deep) "dreaming" to refer to the generation of images that produce desired activations in a trained deep network, and the term now refers to a collection of related approaches.\n\n\n== History ==\nThe DeepDream software, originated in a deep convolutional network codenamed "Inception" after the film of the same name, was developed for the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) in 2014 and released in July 2015.\nThe dreaming idea and name became popular on the internet in 2015 thanks to Google's DeepDream program.  The idea dates from early in the history of neural networks, and similar methods have been used to synthesize visual textures.\nRelated visualization ideas were developed (prior to Google's work) by several research groups.After Google published their techniques and made their code open-source, a number of tools in the form of web services, mobile applications, and desktop software appeared on the market to enable users to transform their own photos.\n\n\n== Process ==\n\nThe software is designed to detect faces and other patterns in images, with the aim of automatically classifying images. However, once trained, the network can also be run in reverse, being asked to adjust the original image slightly so that a given output neuron (e.g. the one for faces or certain animals) yields a higher confidence score. This can be used for visualizations to understand the emergent structure of the neural network better, and is the basis for the DeepDream concept. This reversal procedure is never perfectly clear and unambiguous because it utilizes a one-to-many mapping process. However, after enough reiterations, even imagery initially devoid of the sought features will be adjusted enough that a form of pareidolia results, by which psychedelic and surreal images are generated algorithmically. The optimization resembles backpropagation, however instead of adjusting the network weights, the weights are held fixed and the input is adjusted.\nFor example, an existing image can be altered so that it is "more cat-like", and the resulting enhanced image can be again input to the procedure. This usage resembles the activity of looking for animals or other patterns in clouds.\nApplying gradient descent independently to each pixel of the input produces images in which\nadjacent pixels have little relation and thus the image has too much high frequency information.\nThe generated images can be greatly improved by including a prior or regularizer that prefers inputs\nthat have natural image statistics (without a preference for any particular image), or are simply smooth.\nFor example, Mahendran et al. used the total variation regularizer that prefers images that are piecewise constant. Various regularizers are discussed further in. An in-depth, visual exploration of feature visualization and regularization techniques was published more recently.The cited resemblance of the imagery to LSD- and psilocybin-induced hallucinations is suggestive of a functional resemblance between artificial neural networks and particular layers of the visual cortex.\n\n\n== Usage ==\n\nThe dreaming idea can be applied to hidden (internal) neurons other than those in the output, \nwhich allows exploration of the roles and representations of various parts of the network.\nIt is also possible to optimize the input to satisfy either a single neuron (this usage is sometimes called Activity Maximization) or an entire layer of neurons.\nWhile dreaming is most often used for visualizing networks or producing computer art, it has recently been proposed that adding "dreamed" inputs to the training set can improve training times for abstractions in Computer Science.The DeepDream model has also been demonstrated to have application in the field of art history.DeepDream was used for Foster the People's music video for the song "Doing It for the Money".In 2017, a research group out of the University of Sussex created a Hallucination Machine, applying the DeepDream algorithm to a pre-recorded panoramic video, allowing users to explore virtual reality environments to mimic the experience of psychoactive substances and/or psychopathological conditions.  They were able to demonstrate that the subjective experiences induced by the Hallucination Machine differed significantly from control (non-\u2018hallucinogenic\u2019) videos, while bearing phenomenological similarities to the psychedelic state (following administration of psilocybin).\n\n\n== See also ==\n\nFeature detection (computer vision)\nNeural Style Transfer\nProcedural textures\nTexture synthesis\nAI Art Generators (includes tools that let visitors experiment with DeepDream in the browser).\n\n\n== References ==\n\n\n== External links ==\nDeep Dream, python notebook on GitHub\nMordvintsev, Alexander; Olah, Christopher; Tyka, Mike (June 17, 2015). "Inceptionism: Going Deeper into Neural Networks". Archived from the original on 2015-07-03.