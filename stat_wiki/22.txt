Radical probabilism is a doctrine in philosophy, in particular epistemology, and probability theory that holds that no facts are known for certain. That view holds profound implications for statistical inference. The philosophy is particularly associated with Richard Jeffrey who wittily characterised it with the dictum "It's probabilities all the way down."\n\n\n== Background ==\n\nIn frequentist statistics, Bayes' theorem provides a useful rule for updating a probability when new frequency data becomes available. In Bayesian statistics, the theorem itself plays a more limited role. Bayes' theorem connects probabilities that are held simultaneously. It does not tell the learner how to update probabilities when new evidence becomes available over time. This subtlety was first pointed out in terms by Ian Hacking in 1967.However, adopting Bayes' theorem is a temptation. Suppose that a learner forms probabilities Pold(A & B) = p and Pold(B) = q.\nIf the learner subsequently learns that B is true, nothing in the axioms of probability or the results derived therefrom tells him how to behave. He might be tempted to adopt Bayes' theorem by analogy and set his Pnew(A) = Pold(A | B) = p/q.\nIn fact, that step, Bayes' rule of updating, can be justified, as necessary and sufficient, through a dynamic Dutch book argument that is additional to the arguments used to justify the probability axioms. This argument was first put forward by David Lewis in the 1970s though he never published it. The dynamic Dutch book argument for Bayesian updating has been criticised by Hacking, H. Kyburg, D. Christensen and P. Maher. It was defended by Brian Skyrms.\n\n\n== Certain and uncertain knowledge ==\nThat works when the new data is certain. C. I. Lewis had argued that "If anything is to be probable then something must be certain". There must, on Lewis' account, be some certain facts on which probabilities were conditioned. However, the principle known as Cromwell's rule declares that nothing, apart from a logical law, if that, can ever be known for certain. Jeffrey famously rejected Lewis' dictum. He later quipped, "It's probabilities all the way down," a reference to the "turtles all the way down" metaphor for the infinite regress problem. He called this position radical probabilism.\n\n\n== Conditioning on an uncertainty \u2013 probability kinematics ==\nIn this case Bayes' rule isn't able to capture a mere subjective change in the probability of some critical fact. The new evidence may not have been anticipated or even be capable of being articulated after the event. It seems reasonable, as a starting position, to adopt the law of total probability and extend it to updating in much the same way as was Bayes' theorem.\nPnew(A) = Pold(A | B)Pnew(B) + Pold(A | not-B)Pnew(not-B)Adopting such a rule is sufficient to avoid a Dutch book but not necessary. Jeffrey advocated this as a rule of updating under radical probabilism and called it probability kinematics. Others have named it Jeffrey conditioning.\n\n\n== Alternatives to probability kinematics ==\nProbability kinetics is not the only sufficient updating rule for radical probabilism. Others have been advocated including E. T. Jaynes' maximum entropy principle, and Skyrms' principle of reflection. It turns out that probability kinematics is a special case of maximum entropy inference. However, maximum entropy is not a generalisation of all such sufficient updating rules.\n\n\n== Selected bibliography ==\nJeffrey, R (1990) The Logic of Decision. 2nd ed. University of Chicago Press. ISBN 0-226-39582-0\n\u2014 (1992) Probability and the Art of Judgment. Cambridge University Press. ISBN 0-521-39770-7\n\u2014 (2004) Subjective Probability: The Real Thing. Cambridge University Press. ISBN 0-521-53668-5\nSkyrms, B (2012) From Zeno to Arbitrage: Essays on Quantity, Coherence & Induction. Oxford University Press (Features most of the papers cited below.)\n\n\n== References ==\n\n\n== External links ==\nStanford Encyclopedia of Philosophy entry on